import time
import logging


def timeit(f):
    """ Decorator to time Any Function """

    def timed(*args, **kwargs):
        start_time = time.time()
        result = f(*args, **kwargs)
        end_time = time.time()
        seconds = end_time - start_time
        logging.getLogger("Timer").info("   [-] %s : %2.5f sec, which is %2.5f min, which is %2.5f hour" %
                                        (f.__name__, seconds, seconds / 60, seconds / 3600))
        return result

    return timed


def print_cuda_statistics():
    logger = logging.getLogger("Cuda Statistics")
    logger.setLevel(logging.INFO)

    import sys
    # from subprocess import call
    import torch

    # handler = logging.StreamHandler(sys.stdout)
    # formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    # handler.setFormatter(formatter)
    # logger.addHandler(handler)

    from subprocess import Popen, PIPE

    p = Popen(["nvidia-smi", "--format=csv",
               "--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free"], stdin=PIPE, stdout=PIPE,
              stderr=PIPE)
    output, err = p.communicate(b"input data that is passed to subprocess' stdin")
    nvidia_message = output.decode("utf-8").split("\n")


    logger.info('__Python VERSION:  {}'.format(sys.version))
    logger.info('__pyTorch VERSION:  {}'.format(torch.__version__))
    logger.info('__CUDA VERSION')
    # call(["nvcc", "--version"])
    logger.info('__CUDNN VERSION:  {}'.format(torch.backends.cudnn.version()))
    logger.info('__Number CUDA Devices:  {}'.format(torch.cuda.device_count()))
    logger.info('__Devices')
    logger.info(nvidia_message[0])
    logger.info(nvidia_message[1])
    logger.info('Active CUDA Device: GPU {}'.format(torch.cuda.current_device()))
    logger.info('Available devices  {}'.format(torch.cuda.device_count()))
    logger.info('Current cuda device  {}'.format(torch.cuda.current_device()))
